# Quantization ë¹„êµ ì‹¤í—˜ í”„ë¡œì íŠ¸

EchoNet-Dynamic ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ EF íšŒê·€ ëª¨ë¸ì— Post-Training Quantization (PTQ)ì™€ Quantization-Aware Training (QAT)ë¥¼ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
quantization_project/
â”œâ”€â”€ config.py             # í•˜ì´í¼íŒŒë¼ë¯¸í„° / ê²½ë¡œ ì„¤ì •
â”œâ”€â”€ dataset.py            # EchoNetVideoDataset
â”œâ”€â”€ model.py              # EFRegressionModel (ResNet18 + frame aggregation)
â”œâ”€â”€ train.py              # í•™ìŠµ/í‰ê°€ í•¨ìˆ˜
â”œâ”€â”€ quant_utils.py        # PTQ/QAT ê´€ë ¨ í•¨ìˆ˜
â”œâ”€â”€ metrics.py            # MAE, latency, model size ê³„ì‚° í•¨ìˆ˜
â”œâ”€â”€ main_ptq.py           # PTQ ì‹¤í—˜ ì‹¤í–‰
â”œâ”€â”€ main_qat.py           # QAT ì‹¤í—˜ ì‹¤í–‰
â”œâ”€â”€ run_all.py            # baseline â†’ PTQ â†’ QAT ì „ì²´ ìˆ˜í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ quantization_experiments.ipynb   # Colabìš© ì£¼ë ¥ ë…¸íŠ¸ë¶
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (Google Colab)

1. **í™˜ê²½ ì„¤ì •**
   ```python
   !pip install -r requirements.txt
   ```

2. **ë°ì´í„° ì¤€ë¹„**
   - `/content/sample_echonet/` ë””ë ‰í† ë¦¬ì— EchoNet ìƒ˜í”Œ ë°ì´í„° ì—…ë¡œë“œ
   - `FileList.csv` íŒŒì¼ í¬í•¨ (FileName, EF ì»¬ëŸ¼ í•„ìš”)

3. **ë…¸íŠ¸ë¶ ì‹¤í–‰**
   - `notebooks/quantization_experiments.ipynb` ì—´ê¸°
   - ì…€ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼ (GPU ì„œë²„)

ì‹¤í—˜ ê²°ê³¼ëŠ” ë‹¤ìŒ í•­ëª©ì„ ë¹„êµí•©ë‹ˆë‹¤:

- **MAE (Mean Absolute Error)**: ëª¨ë¸ ì •í™•ë„
- **Model Size (MB)**: ëª¨ë¸ íŒŒì¼ í¬ê¸°
- **Latency (ms/video)**: ì¶”ë¡  ì†ë„

### ìµœì¢… ë¹„êµ í…Œì´ë¸”

| Model | Precision | Size(MB) | MAE | Latency(ms) | Device |
| ----- | --------- | -------- | --- | ----------- | ------ |
| FP32 Baseline | FP32 | 42.71 | 47.41 | 7.57 | GPU |
| PTQ | INT8 | 42.71 | 47.41 | 871.62 | CPU |
| QAT | INT8 | 42.71 | 47.82 | 895.11 | CPU |

**ì£¼ìš” ê´€ì°°**:
- âœ… PTQ: ì •í™•ë„ ê±°ì˜ ìœ ì§€ (0.01% ì¦ê°€)
- âœ… QAT: ì•½ê°„ì˜ ì •í™•ë„ ê°ì†Œ (0.86% ì¦ê°€)í•˜ì§€ë§Œ ì–‘í˜¸
- âš ï¸ Latency: CPU ì‹¤í–‰ìœ¼ë¡œ ì¸í•´ ì¦ê°€ (GPU quantization ì§€ì› ì‹œ ê°œì„  ì˜ˆìƒ)

## ğŸ”§ ì£¼ìš” ëª¨ë“ˆ ì„¤ëª…

### `dataset.py`
- EchoNet ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ ë¡œë”
- ê· ë“±ê°„ê²© frame sampling
- ì „ì²˜ë¦¬ (resize, normalize)

### `model.py`
- ResNet-18 ê¸°ë°˜ EF íšŒê·€ ëª¨ë¸
- Temporal mean poolingìœ¼ë¡œ í”„ë ˆì„ ì§‘ê³„

### `quant_utils.py`
- PTQ: Post-Training Quantization íŒŒì´í”„ë¼ì¸
- QAT: Quantization-Aware Training íŒŒì´í”„ë¼ì¸

### `metrics.py`
- MAE ê³„ì‚°
- Latency ì¸¡ì • (GPU/CPU)
- Model size ê³„ì‚°

## ğŸ“ ì‚¬ìš© ë°©ë²•

### GPU ì„œë²„ ì‹¤í–‰ (ê¶Œì¥)
```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /path/to/2025_edge_computing_task2

# ì „ì²´ ì‹¤í—˜ ì‹¤í–‰ (Baseline í•™ìŠµ í¬í•¨)
python run_all.py \
    --data_root /path/to/echonet_dynamic \
    --train_baseline \
    --batch_size 16

# ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©
python run_all.py \
    --data_root /path/to/echonet_dynamic \
    --no-train_baseline
```

ìì„¸í•œ ë‚´ìš©ì€ `GPU_SERVER_USAGE.md`ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

### ë¡œì»¬ ì‹¤í–‰
```bash
# ì „ì²´ ì‹¤í—˜ (baseline â†’ PTQ â†’ QAT)
python run_all.py --data_root ./sample_echonet_dynamic --train_baseline
```

### Colab ì‹¤í–‰
`notebooks/quantization_experiments.ipynb`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

## âš™ï¸ ì„¤ì • ë³€ê²½

ëª¨ë“  ì„¤ì •ì€ `config.py`ì—ì„œ ê´€ë¦¬ë©ë‹ˆë‹¤:
- ë°ì´í„° ê²½ë¡œ
- í•˜ì´í¼íŒŒë¼ë¯¸í„°
- Quantization ì„¤ì •

## ğŸ“Œ ì°¸ê³ ì‚¬í•­

- ë³¸ ê³¼ì œëŠ” ìƒ˜í”Œ ë°ì´í„°ì…‹(ì•½ 100~200ê°œ)ìœ¼ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤
- Frame sampling: 8~16 frames
- ì´ë¯¸ì§€ í¬ê¸°: 112Ã—112 ë˜ëŠ” 128Ã—128

