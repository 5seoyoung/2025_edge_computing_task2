{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EF Regression Model with Pruning Experiments\n",
        "\n",
        "EchoNet-Dynamic 데이터셋을 활용한 좌심실 박출률(EF) 회귀 모델 및 Pruning 비교 실험\n",
        "\n",
        "## 프로젝트 개요\n",
        "- **모델**: ResNet-18 기반 EF 회귀 모델\n",
        "- **Pruning 방법**: Unstructured Pruning, Structured Pruning\n",
        "- **평가 지표**: MAE, Parameters, Sparsity, Latency\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 환경 설정 및 패키지 설치\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 패키지 설치\n",
        "%pip install torch torchvision opencv-python pandas numpy Pillow matplotlib\n",
        "\n",
        "# GPU 확인\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 데이터 준비\n",
        "\n",
        "### 옵션 A: Google Drive 마운트 (권장)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 전체 데이터 경로 설정 (Drive에 전체 데이터가 있는 경우)\n",
        "# 샘플 데이터를 사용하려면 아래 \"옵션 B: 샘플 데이터 생성\" 셀을 사용하세요\n",
        "FULL_DATA_ROOT = \"/content/drive/MyDrive/echonet_dynamic\"  # 여기를 실제 경로로 수정하세요\n",
        "\n",
        "# 전체 데이터를 사용할 경우\n",
        "# DATA_ROOT = FULL_DATA_ROOT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 옵션 B: 샘플 데이터 사용 (전체 데이터가 너무 큰 경우)\n",
        "\n",
        "이미 Drive에 준비된 샘플 데이터를 사용하거나, 아래 코드로 샘플 데이터를 생성할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 샘플 데이터 사용 설정\n",
        "USE_SAMPLE_DATA = True  # True: 샘플 데이터 사용, False: 전체 데이터 사용\n",
        "\n",
        "if USE_SAMPLE_DATA:\n",
        "    # 이미 Drive에 준비된 샘플 데이터 경로\n",
        "    # 폴더 구조: sample_echonet_dynamic/Videos/*.avi, sample_echonet_dynamic/FileList.csv\n",
        "    DATA_ROOT = \"/content/drive/MyDrive/sample_echonet_dynamic\"  # 여기를 실제 경로로 수정\n",
        "    \n",
        "    from pathlib import Path\n",
        "    sample_path = Path(DATA_ROOT)\n",
        "    \n",
        "    if sample_path.exists():\n",
        "        # 샘플 데이터 정보 확인\n",
        "        filelist_path = sample_path / \"FileList.csv\"\n",
        "        video_dir = sample_path / \"Videos\"\n",
        "        \n",
        "        if filelist_path.exists() and video_dir.exists():\n",
        "            import pandas as pd\n",
        "            df = pd.read_csv(filelist_path)\n",
        "            video_count = len(list(video_dir.glob(\"*.avi\")))\n",
        "            \n",
        "            print(f\"✅ Sample dataset found:\")\n",
        "            print(f\"  Location: {DATA_ROOT}\")\n",
        "            print(f\"  Videos in FileList.csv: {len(df)}\")\n",
        "            print(f\"  Video files in Videos/: {video_count}\")\n",
        "            \n",
        "            # Split distribution 확인\n",
        "            if 'Split' in df.columns:\n",
        "                print(f\"\\nSplit distribution:\")\n",
        "                for split in ['TRAIN', 'VAL', 'TEST']:\n",
        "                    count = len(df[df['Split'] == split])\n",
        "                    print(f\"  {split}: {count}\")\n",
        "        else:\n",
        "            print(f\"❌ Sample dataset structure incorrect!\")\n",
        "            print(f\"  Expected: {filelist_path}\")\n",
        "            print(f\"  Expected: {video_dir}\")\n",
        "            DATA_ROOT = None\n",
        "    else:\n",
        "        print(f\"❌ Sample dataset not found at {DATA_ROOT}\")\n",
        "        print(\"Please check the path or upload sample data to Drive\")\n",
        "        DATA_ROOT = None\n",
        "else:\n",
        "    # 전체 데이터 사용\n",
        "    DATA_ROOT = \"/content/drive/MyDrive/echonet_dynamic\"  # 여기를 실제 경로로 수정\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 옵션 C: 샘플 데이터 생성 (필요한 경우)\n",
        "\n",
        "샘플 데이터가 아직 없다면, 전체 데이터에서 샘플을 생성할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 샘플 데이터 생성 코드 (필요한 경우에만 실행)\n",
        "# 이미 샘플 데이터가 있다면 이 셀은 건너뛰세요\n",
        "\n",
        "CREATE_SAMPLE = False  # True로 설정하면 샘플 데이터 생성\n",
        "\n",
        "if CREATE_SAMPLE:\n",
        "    import pandas as pd\n",
        "    import shutil\n",
        "    from pathlib import Path\n",
        "    import random\n",
        "    \n",
        "    # 원본 데이터 경로\n",
        "    SOURCE_DATA_ROOT = \"/content/drive/MyDrive/echonet_dynamic\"  # 전체 데이터 경로\n",
        "    TARGET_DATA_ROOT = \"/content/drive/MyDrive/sample_echonet_dynamic\"  # 샘플 저장 경로\n",
        "    \n",
        "    SAMPLE_SIZES = {\n",
        "        'TRAIN': 100,  # Train 샘플 수\n",
        "        'VAL': 20,     # Val 샘플 수\n",
        "        'TEST': 20     # Test 샘플 수\n",
        "    }\n",
        "    \n",
        "    source_path = Path(SOURCE_DATA_ROOT)\n",
        "    target_path = Path(TARGET_DATA_ROOT)\n",
        "    \n",
        "    if source_path.exists():\n",
        "        print(\"Creating sample dataset...\")\n",
        "        \n",
        "        # Read original FileList.csv\n",
        "        filelist_path = source_path / \"FileList.csv\"\n",
        "        df = pd.read_csv(filelist_path)\n",
        "        print(f\"Original dataset: {len(df)} videos\")\n",
        "        \n",
        "        # Create target directories\n",
        "        target_path.mkdir(exist_ok=True, parents=True)\n",
        "        (target_path / \"Videos\").mkdir(exist_ok=True, parents=True)\n",
        "        \n",
        "        # Sample videos by split\n",
        "        sample_df_list = []\n",
        "        random.seed(42)\n",
        "        \n",
        "        for split, num_samples in SAMPLE_SIZES.items():\n",
        "            split_df = df[df['Split'] == split].copy()\n",
        "            if len(split_df) < num_samples:\n",
        "                print(f\"Warning: Only {len(split_df)} samples in {split}, using all\")\n",
        "                selected_df = split_df\n",
        "            else:\n",
        "                selected_df = split_df.sample(n=num_samples, random_state=42)\n",
        "            \n",
        "            print(f\"{split}: Selected {len(selected_df)} samples\")\n",
        "            sample_df_list.append(selected_df)\n",
        "            \n",
        "            # Copy video files\n",
        "            source_video_dir = source_path / \"Videos\"\n",
        "            target_video_dir = target_path / \"Videos\"\n",
        "            \n",
        "            copied = 0\n",
        "            for _, row in selected_df.iterrows():\n",
        "                filename = row['FileName']\n",
        "                if not filename.endswith('.avi'):\n",
        "                    filename = filename + '.avi'\n",
        "                \n",
        "                source_video = source_video_dir / filename\n",
        "                target_video = target_video_dir / filename\n",
        "                \n",
        "                if source_video.exists():\n",
        "                    shutil.copy2(source_video, target_video)\n",
        "                    copied += 1\n",
        "                    if copied % 10 == 0:\n",
        "                        print(f\"  Copied {copied}/{len(selected_df)} videos...\")\n",
        "                else:\n",
        "                    print(f\"Warning: Video not found: {source_video}\")\n",
        "        \n",
        "        # Combine and save sample FileList.csv\n",
        "        sample_df = pd.concat(sample_df_list, ignore_index=True)\n",
        "        sample_filelist_path = target_path / \"FileList.csv\"\n",
        "        sample_df.to_csv(sample_filelist_path, index=False)\n",
        "        \n",
        "        print(f\"\\n✅ Sample dataset created:\")\n",
        "        print(f\"  Total videos: {len(sample_df)}\")\n",
        "        print(f\"  Location: {target_path}\")\n",
        "        \n",
        "        # Print split distribution\n",
        "        print(f\"\\nSplit distribution:\")\n",
        "        for split in ['TRAIN', 'VAL', 'TEST']:\n",
        "            count = len(sample_df[sample_df['Split'] == split])\n",
        "            print(f\"  {split}: {count}\")\n",
        "    else:\n",
        "        print(f\"❌ Source data not found at {SOURCE_DATA_ROOT}\")\n",
        "else:\n",
        "    print(\"Skipping sample data creation (CREATE_SAMPLE = False)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 필요한 모듈 로드\n",
        "\n",
        "아래 셀들을 실행하여 프로젝트 파일들을 업로드하거나, GitHub에서 클론하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 방법 1: GitHub에서 클론 (권장)\n",
        "!git clone https://github.com/5seoyoung/2025_edge_computing_task1.git\n",
        "import sys\n",
        "sys.path.append('/content/2025_edge_computing_task1')\n",
        "\n",
        "# 방법 2: 파일 직접 업로드\n",
        "# from google.colab import files\n",
        "# files.upload()  # config.py, dataset.py, model.py 등을 업로드\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 설정 및 모듈 임포트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime\n",
        "import sys\n",
        "\n",
        "# 프로젝트 경로 추가\n",
        "sys.path.append('/content/2025_edge_computing_task1')\n",
        "\n",
        "# 모듈 임포트\n",
        "from config import Config\n",
        "from dataset import create_data_loaders\n",
        "from model import EFRegressionModel\n",
        "from train import train_model, load_checkpoint\n",
        "from prune_utils import apply_pruning_experiment\n",
        "from metrics import count_params, calculate_sparsity, evaluate_model, measure_latency\n",
        "\n",
        "# Colab용 설정 업데이트\n",
        "# 위에서 설정한 DATA_ROOT를 사용\n",
        "if 'DATA_ROOT' in locals() and DATA_ROOT is not None:\n",
        "    Config.DATA_ROOT = Path(DATA_ROOT)\n",
        "    Config.VIDEO_DIR = Config.DATA_ROOT / \"Videos\"\n",
        "    Config.FILELIST_PATH = Config.DATA_ROOT / \"FileList.csv\"\n",
        "    print(f\"✅ Using data from: {Config.DATA_ROOT}\")\n",
        "else:\n",
        "    print(\"❌ DATA_ROOT not set! Please run data preparation cells above.\")\n",
        "    raise ValueError(\"DATA_ROOT must be set. Check data preparation section.\")\n",
        "\n",
        "# 디렉토리 생성\n",
        "Config.setup_directories()\n",
        "\n",
        "# 디바이스 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Data root: {Config.DATA_ROOT}\")\n",
        "print(f\"Video dir: {Config.VIDEO_DIR}\")\n",
        "print(f\"FileList: {Config.FILELIST_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 데이터 로딩\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 경로 확인\n",
        "if not Config.VIDEO_DIR.exists():\n",
        "    raise FileNotFoundError(f\"Video directory not found: {Config.VIDEO_DIR}\")\n",
        "if not Config.FILELIST_PATH.exists():\n",
        "    raise FileNotFoundError(f\"FileList.csv not found: {Config.FILELIST_PATH}\")\n",
        "\n",
        "# 데이터 로더 생성\n",
        "print(\"Loading dataset...\")\n",
        "train_loader, val_loader, test_loader = create_data_loaders(\n",
        "    video_dir=Config.VIDEO_DIR,\n",
        "    filelist_path=Config.FILELIST_PATH,\n",
        "    num_frames=Config.NUM_FRAMES,\n",
        "    image_size=Config.IMAGE_SIZE,\n",
        "    batch_size=Config.BATCH_SIZE,\n",
        "    num_workers=Config.NUM_WORKERS\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_loader.dataset)}\")\n",
        "print(f\"Val samples: {len(val_loader.dataset)}\")\n",
        "print(f\"Test samples: {len(test_loader.dataset)}\")\n",
        "\n",
        "# Latency 측정용 샘플 입력 준비\n",
        "sample_videos, _ = next(iter(val_loader))\n",
        "sample_input = sample_videos[:1].to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Baseline 모델 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline 모델 생성\n",
        "baseline_model = EFRegressionModel(\n",
        "    num_frames=Config.NUM_FRAMES,\n",
        "    pretrained=True\n",
        ")\n",
        "\n",
        "baseline_checkpoint_path = Config.CHECKPOINT_DIR / \"baseline_best.pth\"\n",
        "\n",
        "# Baseline 모델 학습 또는 로드\n",
        "if not baseline_checkpoint_path.exists():\n",
        "    print(\"Training baseline model...\")\n",
        "    baseline_model = train_model(\n",
        "        model=baseline_model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs=Config.NUM_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        device=device,\n",
        "        checkpoint_dir=Config.CHECKPOINT_DIR\n",
        "    )\n",
        "    \n",
        "    # 최종 모델 저장\n",
        "    torch.save(baseline_model.state_dict(), baseline_checkpoint_path)\n",
        "    print(f\"Baseline model saved to {baseline_checkpoint_path}\")\n",
        "else:\n",
        "    print(f\"Loading baseline model from {baseline_checkpoint_path}\")\n",
        "    baseline_model.load_state_dict(torch.load(baseline_checkpoint_path, map_location=device))\n",
        "    baseline_model = baseline_model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Baseline 모델 평가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline 평가\n",
        "print(\"Evaluating baseline model...\")\n",
        "baseline_model.eval()\n",
        "baseline_results = evaluate_model(baseline_model, test_loader, device)\n",
        "baseline_params = count_params(baseline_model)\n",
        "baseline_sparsity = calculate_sparsity(baseline_model)\n",
        "baseline_latency = measure_latency(\n",
        "    baseline_model, sample_input, device,\n",
        "    Config.LATENCY_WARMUP_ITERATIONS,\n",
        "    Config.LATENCY_MEASURE_ITERATIONS\n",
        ")\n",
        "\n",
        "baseline_summary = {\n",
        "    'model_type': 'baseline',\n",
        "    'num_params': baseline_params,\n",
        "    'sparsity': baseline_sparsity,\n",
        "    'MAE': baseline_results['MAE'],\n",
        "    'latency_ms_per_video': baseline_latency\n",
        "}\n",
        "\n",
        "print(f\"\\nBaseline Results:\")\n",
        "print(f\"  Parameters: {baseline_params:,}\")\n",
        "print(f\"  Sparsity: {baseline_sparsity:.4f}\")\n",
        "print(f\"  MAE: {baseline_results['MAE']:.4f}\")\n",
        "print(f\"  Latency: {baseline_latency:.4f} ms/video\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Unstructured Pruning 실험\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"Unstructured Pruning Experiments\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "unstructured_results = apply_pruning_experiment(\n",
        "    model=baseline_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    pruning_type=\"unstructured\",\n",
        "    pruning_ratios=Config.UNSTRUCTURED_PRUNING_RATIOS,\n",
        "    fine_tune_epochs=Config.FINE_TUNE_EPOCHS,\n",
        "    learning_rate=Config.LEARNING_RATE * 0.1,  # Lower LR for fine-tuning\n",
        "    device=device,\n",
        "    sample_input=sample_input\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Structured Pruning 실험\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"Structured Pruning Experiments\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Unstructured pruning이 모델을 수정했으므로 baseline 다시 로드\n",
        "baseline_model.load_state_dict(torch.load(baseline_checkpoint_path, map_location=device))\n",
        "baseline_model = baseline_model.to(device)\n",
        "\n",
        "structured_results = apply_pruning_experiment(\n",
        "    model=baseline_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    pruning_type=\"structured\",\n",
        "    pruning_ratios=Config.STRUCTURED_PRUNING_RATIOS,\n",
        "    fine_tune_epochs=Config.FINE_TUNE_EPOCHS,\n",
        "    learning_rate=Config.LEARNING_RATE * 0.1,\n",
        "    device=device,\n",
        "    sample_input=sample_input\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 결과 저장 및 시각화\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모든 결과 저장\n",
        "all_results = {\n",
        "    'baseline': baseline_summary,\n",
        "    'unstructured_pruning': unstructured_results,\n",
        "    'structured_pruning': structured_results,\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'config': {\n",
        "        'num_frames': Config.NUM_FRAMES,\n",
        "        'image_size': Config.IMAGE_SIZE,\n",
        "        'batch_size': Config.BATCH_SIZE,\n",
        "        'num_epochs': Config.NUM_EPOCHS,\n",
        "        'learning_rate': Config.LEARNING_RATE,\n",
        "        'fine_tune_epochs': Config.FINE_TUNE_EPOCHS\n",
        "    }\n",
        "}\n",
        "\n",
        "# JSON으로 저장\n",
        "results_path = Config.RESULTS_DIR / f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "print(f\"Results saved to: {results_path}\")\n",
        "\n",
        "# 요약 테이블 생성\n",
        "summary_data = []\n",
        "\n",
        "# Baseline\n",
        "summary_data.append({\n",
        "    'Model': 'Baseline',\n",
        "    'Pruning Ratio': '-',\n",
        "    'Parameters': baseline_summary['num_params'],\n",
        "    'Sparsity': f\"{baseline_summary['sparsity']:.4f}\",\n",
        "    'MAE': f\"{baseline_summary['MAE']:.4f}\",\n",
        "    'Latency (ms/video)': f\"{baseline_summary['latency_ms_per_video']:.4f}\"\n",
        "})\n",
        "\n",
        "# Unstructured pruning\n",
        "for result in unstructured_results:\n",
        "    summary_data.append({\n",
        "        'Model': 'Unstructured',\n",
        "        'Pruning Ratio': f\"{result['pruning_ratio']:.2f}\",\n",
        "        'Parameters': result['num_params'],\n",
        "        'Sparsity': f\"{result['sparsity']:.4f}\",\n",
        "        'MAE': f\"{result['MAE']:.4f}\",\n",
        "        'Latency (ms/video)': f\"{result['latency_ms_per_video']:.4f}\" if result['latency_ms_per_video'] else 'N/A'\n",
        "})\n",
        "\n",
        "# Structured pruning\n",
        "for result in structured_results:\n",
        "    summary_data.append({\n",
        "        'Model': 'Structured',\n",
        "        'Pruning Ratio': f\"{result['pruning_ratio']:.2f}\",\n",
        "        'Parameters': result['num_params'],\n",
        "        'Sparsity': f\"{result['sparsity']:.4f}\",\n",
        "        'MAE': f\"{result['MAE']:.4f}\",\n",
        "        'Latency (ms/video)': f\"{result['latency_ms_per_video']:.4f}\" if result['latency_ms_per_video'] else 'N/A'\n",
        "})\n",
        "\n",
        "# 테이블 출력\n",
        "df_summary = pd.DataFrame(summary_data)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Summary Table\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n\" + df_summary.to_string(index=False))\n",
        "\n",
        "# CSV로 저장\n",
        "csv_path = Config.RESULTS_DIR / f\"summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "df_summary.to_csv(csv_path, index=False)\n",
        "print(f\"\\nSummary table saved to: {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 결과 시각화 (선택사항)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 결과 시각화\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# 1. MAE 비교\n",
        "ax1 = axes[0, 0]\n",
        "models = ['Baseline']\n",
        "mae_values = [baseline_summary['MAE']]\n",
        "\n",
        "for result in unstructured_results:\n",
        "    models.append(f\"Unstructured\\n({result['pruning_ratio']:.1f})\")\n",
        "    mae_values.append(result['MAE'])\n",
        "\n",
        "for result in structured_results:\n",
        "    models.append(f\"Structured\\n({result['pruning_ratio']:.1f})\")\n",
        "    mae_values.append(result['MAE'])\n",
        "\n",
        "ax1.bar(models, mae_values, color=['blue'] + ['orange']*len(unstructured_results) + ['green']*len(structured_results))\n",
        "ax1.set_ylabel('MAE')\n",
        "ax1.set_title('MAE Comparison')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 2. Parameters 비교\n",
        "ax2 = axes[0, 1]\n",
        "param_values = [baseline_summary['num_params']]\n",
        "for result in unstructured_results:\n",
        "    param_values.append(result['num_params'])\n",
        "for result in structured_results:\n",
        "    param_values.append(result['num_params'])\n",
        "\n",
        "ax2.bar(models, param_values, color=['blue'] + ['orange']*len(unstructured_results) + ['green']*len(structured_results))\n",
        "ax2.set_ylabel('Number of Parameters')\n",
        "ax2.set_title('Parameters Comparison')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
        "\n",
        "# 3. Sparsity 비교\n",
        "ax3 = axes[1, 0]\n",
        "sparsity_values = [baseline_summary['sparsity']]\n",
        "for result in unstructured_results:\n",
        "    sparsity_values.append(result['sparsity'])\n",
        "for result in structured_results:\n",
        "    sparsity_values.append(result['sparsity'])\n",
        "\n",
        "ax3.bar(models, sparsity_values, color=['blue'] + ['orange']*len(unstructured_results) + ['green']*len(structured_results))\n",
        "ax3.set_ylabel('Sparsity')\n",
        "ax3.set_title('Sparsity Comparison')\n",
        "ax3.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 4. Latency 비교\n",
        "ax4 = axes[1, 1]\n",
        "latency_values = [baseline_summary['latency_ms_per_video']]\n",
        "for result in unstructured_results:\n",
        "    if result['latency_ms_per_video']:\n",
        "        latency_values.append(result['latency_ms_per_video'])\n",
        "    else:\n",
        "        latency_values.append(0)\n",
        "for result in structured_results:\n",
        "    if result['latency_ms_per_video']:\n",
        "        latency_values.append(result['latency_ms_per_video'])\n",
        "    else:\n",
        "        latency_values.append(0)\n",
        "\n",
        "ax4.bar(models, latency_values, color=['blue'] + ['orange']*len(unstructured_results) + ['green']*len(structured_results))\n",
        "ax4.set_ylabel('Latency (ms/video)')\n",
        "ax4.set_title('Latency Comparison')\n",
        "ax4.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 결과 다운로드 (Colab에서)\n",
        "print(\"\\nTo download results:\")\n",
        "print(f\"from google.colab import files\")\n",
        "print(f\"files.download('{results_path}')\")\n",
        "print(f\"files.download('{csv_path}')\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. 결과 다운로드 (Colab에서)\n",
        "\n",
        "실험 결과를 다운로드하려면 아래 셀을 실행하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결과 파일 다운로드\n",
        "from google.colab import files\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# 최신 결과 파일 찾기\n",
        "result_files = glob.glob(str(Config.RESULTS_DIR / \"results_*.json\"))\n",
        "csv_files = glob.glob(str(Config.RESULTS_DIR / \"summary_*.csv\"))\n",
        "\n",
        "if result_files:\n",
        "    latest_result = max(result_files, key=os.path.getctime)\n",
        "    files.download(latest_result)\n",
        "    print(f\"Downloaded: {latest_result}\")\n",
        "\n",
        "if csv_files:\n",
        "    latest_csv = max(csv_files, key=os.path.getctime)\n",
        "    files.download(latest_csv)\n",
        "    print(f\"Downloaded: {latest_csv}\")\n",
        "\n",
        "# 체크포인트 다운로드 (선택사항)\n",
        "# files.download(str(baseline_checkpoint_path))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
