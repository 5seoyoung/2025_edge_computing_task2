# GPU ì„œë²„ì—ì„œ ì‹¤í–‰í•˜ê¸°

GPU ì„œë²„ì—ì„œ ì‹¤í—˜ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

## ğŸ” í˜„ì¬ ì½”ë“œì˜ GPU/CPU ì²˜ë¦¬ ë°©ì‹

### ìë™ ë””ë°”ì´ìŠ¤ ì„ íƒ
- **í•™ìŠµ/í‰ê°€**: GPUê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ GPU ì‚¬ìš© (`config.DEVICE`ê°€ ìë™ìœ¼ë¡œ `"cuda"`ë¡œ ì„¤ì •)
- **Quantization**: Dynamic Quantizationì€ CPUì—ì„œë§Œ ì‘ë™í•˜ë¯€ë¡œ ìë™ìœ¼ë¡œ CPUë¡œ ì´ë™
- **ê²°ê³¼**: í•™ìŠµì€ ë¹ ë¥´ê²Œ, quantizationì€ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™

### ì½”ë“œ ë™ì‘ íë¦„
1. **Baseline í•™ìŠµ**: GPUì—ì„œ í•™ìŠµ (ë¹ ë¦„)
2. **PTQ/QAT**: 
   - ëª¨ë¸ì„ CPUë¡œ ì´ë™
   - Dynamic Quantization ì ìš© (CPUì—ì„œë§Œ ì‘ë™)
   - í‰ê°€ëŠ” CPUì—ì„œ ìˆ˜í–‰

## ğŸš€ GPU ì„œë²„ì—ì„œ ì‹¤í–‰í•˜ê¸°

### 1. ì „ì²´ ì‹¤í—˜ ì‹¤í–‰ (ê¶Œì¥)

```bash
# Baseline í•™ìŠµë¶€í„° PTQ, QATê¹Œì§€ ëª¨ë‘ ì‹¤í–‰
python run_all.py \
    --data_root /path/to/echonet_dynamic \
    --train_baseline \
    --batch_size 16 \
    --num_epochs 20 \
    --qat_epochs 5
```

### 2. ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜

```bash
# ì´ë¯¸ í•™ìŠµëœ Baseline ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°
python run_all.py \
    --data_root /path/to/echonet_dynamic \
    --no-train_baseline
```

### 3. ê°œë³„ ì‹¤í—˜ ì‹¤í–‰

```bash
# PTQë§Œ ì‹¤í–‰
python main_ptq.py --data_root /path/to/echonet_dynamic

# QATë§Œ ì‹¤í–‰
python main_qat.py --data_root /path/to/echonet_dynamic
```

## ğŸ“ GPU ì„œë²„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ

`run_gpu_server.sh` íŒŒì¼ì„ ìƒì„±:

```bash
#!/bin/bash
# GPU ì„œë²„ì—ì„œ ì‹¤í—˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

# ë°ì´í„° ê²½ë¡œ (ì„œë²„ì˜ ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •)
DATA_ROOT="/home/work/edgetask2/data/echonet_dynamic"

# GPU í™•ì¸
echo "Checking GPU availability..."
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU count: {torch.cuda.device_count()}'); print(f'GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"

# ì „ì²´ ì‹¤í—˜ ì‹¤í–‰
python run_all.py \
    --data_root "$DATA_ROOT" \
    --train_baseline \
    --batch_size 16 \
    --num_epochs 20 \
    --qat_epochs 5 \
    --checkpoint_dir ./checkpoints \
    --results_dir ./results

echo "âœ… Experiments completed!"
```

ì‹¤í–‰:
```bash
chmod +x run_gpu_server.sh
./run_gpu_server.sh
```

## âš™ï¸ GPU ì„œë²„ì—ì„œì˜ ë™ì‘

### í•™ìŠµ ë‹¨ê³„ (GPU ì‚¬ìš©)
- **Baseline í•™ìŠµ**: GPUì—ì„œ ë¹ ë¥´ê²Œ í•™ìŠµ
- **QAT Fine-tuning**: GPUì—ì„œ í•™ìŠµ (5 epochs)

### Quantization ë‹¨ê³„ (CPU ì‚¬ìš©)
- **PTQ/QAT Conversion**: 
  - ëª¨ë¸ì´ ìë™ìœ¼ë¡œ CPUë¡œ ì´ë™
  - Dynamic Quantization ì ìš© (CPUì—ì„œë§Œ ì‘ë™)
  - í‰ê°€ë„ CPUì—ì„œ ìˆ˜í–‰

### ì„±ëŠ¥ ì°¨ì´
- **í•™ìŠµ ì†ë„**: GPU ì‚¬ìš© ì‹œ CPU ëŒ€ë¹„ 10-50ë°° ë¹ ë¦„
- **Quantization**: CPUì—ì„œ ìˆ˜í–‰ (GPU ì§€ì› ì—†ìŒ)
- **í‰ê°€ ì†ë„**: Quantized ëª¨ë¸ì€ CPUì—ì„œ í‰ê°€

## ğŸ”§ í™˜ê²½ ì„¤ì •

### 1. ê°€ìƒí™˜ê²½ í™œì„±í™” (í•„ìš”ì‹œ)

```bash
# conda í™˜ê²½
conda activate your_env

# ë˜ëŠ” venv
source venv/bin/activate
```

### 2. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 3. GPU í™•ì¸

```bash
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
```

## ğŸ“Š ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„ (GPU ì„œë²„ ê¸°ì¤€)

- **Baseline í•™ìŠµ** (20 epochs): ~10-30ë¶„ (GPU ì‚¬ìš©)
- **PTQ**: ~5-10ë¶„ (CPU quantization)
- **QAT Fine-tuning** (5 epochs): ~5-15ë¶„ (GPU ì‚¬ìš©)
- **QAT Quantization**: ~5-10ë¶„ (CPU quantization)

**ì´ ì˜ˆìƒ ì‹œê°„**: ~30-60ë¶„

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ë°ì´í„° ê²½ë¡œ**: `--data_root`ëŠ” Videos/ ë””ë ‰í† ë¦¬ì™€ FileList.csvê°€ ìˆëŠ” ìƒìœ„ ë””ë ‰í† ë¦¬
2. **ë©”ëª¨ë¦¬**: GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ë©´ `--batch_size`ë¥¼ ì¤„ì´ì„¸ìš” (ì˜ˆ: 8 ë˜ëŠ” 4)
3. **Quantization**: Dynamic Quantizationì€ CPUì—ì„œë§Œ ì‘ë™í•˜ë¯€ë¡œ, quantization ë‹¨ê³„ëŠ” CPUë¡œ ìë™ ì´ë™ë©ë‹ˆë‹¤
4. **ê²°ê³¼**: ëª¨ë“  ê²°ê³¼ëŠ” `results/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤

## ğŸ› ë¬¸ì œ í•´ê²°

### GPUê°€ ì¸ì‹ë˜ì§€ ì•ŠëŠ” ê²½ìš°
```bash
# PyTorch CUDA ë²„ì „ í™•ì¸
python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"

# CUDA ë²„ì „ í™•ì¸
nvidia-smi
```

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
python run_all.py --data_root /path/to/data --batch_size 4
```

### Quantization ì˜¤ë¥˜
- Dynamic Quantizationì€ CPUì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤
- ì½”ë“œê°€ ìë™ìœ¼ë¡œ CPUë¡œ ì´ë™í•˜ë¯€ë¡œ ìˆ˜ë™ ì¡°ì‘ ë¶ˆí•„ìš”

## ğŸ“ ì¶œë ¥ íŒŒì¼

ì‹¤í—˜ ì™„ë£Œ í›„:
- `results/all_results.json`: ì „ì²´ ê²°ê³¼
- `results/comparison_results.csv`: ë¹„êµ í…Œì´ë¸”
- `checkpoints/best_model.pth`: Baseline ëª¨ë¸
- `results/*.png`: ì‹œê°í™” ì°¨íŠ¸

## ğŸ¯ ë¹ ë¥¸ ì‹œì‘ ì˜ˆì‹œ

```bash
# 1. ë°ì´í„° ê²½ë¡œ í™•ì¸
ls /path/to/echonet_dynamic/Videos/
ls /path/to/echonet_dynamic/FileList.csv

# 2. ì „ì²´ ì‹¤í—˜ ì‹¤í–‰
python run_all.py \
    --data_root /path/to/echonet_dynamic \
    --train_baseline

# 3. ê²°ê³¼ í™•ì¸
cat results/comparison_results.csv
ls results/*.png
```

