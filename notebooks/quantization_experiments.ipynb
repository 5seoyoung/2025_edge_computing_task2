{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quantization 비교 실험 - EchoNet-Dynamic EF 회귀 모델\n",
        "\n",
        "이 노트북은 Post-Training Quantization (PTQ)와 Quantization-Aware Training (QAT)를 비교하는 실험을 수행합니다.\n",
        "\n",
        "## 실험 목표\n",
        "- Baseline (FP32) 모델 학습\n",
        "- PTQ 적용 및 성능 측정\n",
        "- QAT 적용 및 성능 측정\n",
        "- 세 모델의 MAE, Model Size, Latency 비교\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 환경 체크 및 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU/CPU 체크\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"\\nUsing device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요한 패키지 설치\n",
        "%pip install -q opencv-python pandas tqdm matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 프로젝트 파일들을 Colab에 업로드하거나 GitHub에서 클론\n",
        "# 방법 1: 파일 업로드 (Colab의 파일 메뉴에서)\n",
        "# 방법 2: GitHub에서 클론\n",
        "# !git clone <your-repo-url>\n",
        "# %cd <repo-directory>\n",
        "\n",
        "# 또는 직접 파일들을 복사/붙여넣기\n",
        "\n",
        "# 현재 디렉토리 확인\n",
        "import os\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "print(f\"Files in current directory: {os.listdir('.')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 데이터 준비\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: 샘플 EchoNet 데이터를 /content/sample_echonet/ 에 업로드하세요\n",
        "# 구조:\n",
        "# /content/sample_echonet/\n",
        "#   ├── Videos/\n",
        "#   │   ├── video1.avi\n",
        "#   │   ├── video2.avi\n",
        "#   │   └── ...\n",
        "#   └── FileList.csv  # FileName, EF 컬럼 포함\n",
        "\n",
        "# 데이터 경로 확인\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path(\"/content/sample_echonet\")  # TODO: 실제 경로로 수정\n",
        "VIDEO_DIR = BASE_DIR / \"Videos\"\n",
        "FILELIST_PATH = BASE_DIR / \"FileList.csv\"\n",
        "\n",
        "print(f\"Video directory exists: {VIDEO_DIR.exists()}\")\n",
        "print(f\"FileList exists: {FILELIST_PATH.exists()}\")\n",
        "\n",
        "if FILELIST_PATH.exists():\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(FILELIST_PATH)\n",
        "    print(f\"\\nFileList shape: {df.shape}\")\n",
        "    print(f\"Columns: {df.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 모듈 import 및 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 프로젝트 모듈 import\n",
        "# 노트북이 프로젝트 루트에 있다고 가정\n",
        "import sys\n",
        "sys.path.append('..')  # 상위 디렉토리 추가\n",
        "\n",
        "# 또는 절대 경로 사용\n",
        "# sys.path.append('/content/your-project-path')\n",
        "\n",
        "import config\n",
        "from dataset import get_dataloaders\n",
        "from model import create_model\n",
        "from train import train_model, load_checkpoint\n",
        "from quant_utils import apply_ptq, apply_qat\n",
        "from metrics import evaluate_model_performance\n",
        "from main_ptq import run_ptq_experiment\n",
        "from main_qat import run_qat_experiment\n",
        "from run_all import run_all_experiments\n",
        "import torch.nn as nn\n",
        "\n",
        "# Config 업데이트 (Colab 경로에 맞게)\n",
        "config.BASE_DIR = BASE_DIR\n",
        "config.VIDEO_DIR = VIDEO_DIR\n",
        "config.FILELIST_PATH = FILELIST_PATH\n",
        "config.DEVICE = device\n",
        "\n",
        "print(\"Modules imported successfully!\")\n",
        "print(f\"Config updated:\")\n",
        "print(f\"  BASE_DIR: {config.BASE_DIR}\")\n",
        "print(f\"  VIDEO_DIR: {config.VIDEO_DIR}\")\n",
        "print(f\"  FILELIST_PATH: {config.FILELIST_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 데이터 로더 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/Val 데이터 로더 생성\n",
        "train_loader, val_loader = get_dataloaders(\n",
        "    video_dir=config.VIDEO_DIR,\n",
        "    filelist_path=config.FILELIST_PATH,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    num_workers=0,  # Colab에서는 0 권장\n",
        "    num_frames=config.NUM_FRAMES,\n",
        "    img_size=config.IMG_SIZE,\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "\n",
        "# 샘플 데이터 확인\n",
        "sample_video, sample_ef = next(iter(train_loader))\n",
        "print(f\"\\nSample video shape: {sample_video.shape}\")  # (B, N, C, H, W)\n",
        "print(f\"Sample EF label: {sample_ef[:5]}\")  # 첫 5개 샘플\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Baseline 모델 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline 모델 생성\n",
        "model = create_model()\n",
        "print(f\"Model created: {model.__class__.__name__}\")\n",
        "\n",
        "# 모델 파라미터 수 확인\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline 모델 학습\n",
        "# TODO: 이미 학습된 모델이 있다면 이 셀을 스킵하고 다음 셀에서 로드하세요\n",
        "\n",
        "history = train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs=config.NUM_EPOCHS,\n",
        "    learning_rate=config.LEARNING_RATE,\n",
        "    weight_decay=config.WEIGHT_DECAY,\n",
        "    device=config.DEVICE,\n",
        "    checkpoint_dir=config.CHECKPOINT_DIR,\n",
        "    save_best=True,\n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 학습 히스토리 시각화 (optional)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if 'history' in locals():\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    \n",
        "    # Loss\n",
        "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
        "    axes[0].plot(history['val_loss'], label='Val Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # MAE\n",
        "    axes[1].plot(history['val_mae'], label='Val MAE')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('MAE')\n",
        "    axes[1].set_title('Validation MAE')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Baseline 모델 성능 측정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline 모델 로드 (이미 학습된 경우)\n",
        "baseline_checkpoint = config.CHECKPOINT_DIR / \"best_model.pth\"\n",
        "\n",
        "if baseline_checkpoint.exists():\n",
        "    model = create_model()\n",
        "    checkpoint = load_checkpoint(model, baseline_checkpoint, config.DEVICE)\n",
        "    print(f\"Loaded baseline model from {baseline_checkpoint}\")\n",
        "    if 'val_mae' in checkpoint:\n",
        "        print(f\"Best MAE: {checkpoint['val_mae']:.4f}\")\n",
        "else:\n",
        "    print(\"Baseline checkpoint not found. Please train the model first.\")\n",
        "\n",
        "# Baseline 성능 측정\n",
        "criterion = nn.MSELoss()\n",
        "baseline_performance = evaluate_model_performance(\n",
        "    model,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    device=config.DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "print(\"\\n=== Baseline (FP32) Performance ===\")\n",
        "print(f\"MAE: {baseline_performance['mae']:.4f}\")\n",
        "print(f\"Model Size: {baseline_performance['size_mb']:.4f} MB\")\n",
        "print(f\"Latency: {baseline_performance['latency_ms']:.4f} ms/video\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Post-Training Quantization (PTQ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PTQ 실험 실행\n",
        "ptq_results = run_ptq_experiment(\n",
        "    baseline_checkpoint_path=baseline_checkpoint,\n",
        "    save_results=True,\n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Quantization-Aware Training (QAT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# QAT 실험 실행\n",
        "qat_results = run_qat_experiment(\n",
        "    baseline_checkpoint_path=baseline_checkpoint,\n",
        "    save_results=True,\n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 최종 비교 결과\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 전체 결과 비교 테이블 생성\n",
        "import pandas as pd\n",
        "\n",
        "comparison_data = [\n",
        "    {\n",
        "        'Model': 'FP32 Baseline',\n",
        "        'Precision': 'FP32',\n",
        "        'Size (MB)': f\"{baseline_performance['size_mb']:.4f}\",\n",
        "        'MAE': f\"{baseline_performance['mae']:.4f}\",\n",
        "        'Latency (ms)': f\"{baseline_performance['latency_ms']:.4f}\",\n",
        "    },\n",
        "    {\n",
        "        'Model': 'PTQ',\n",
        "        'Precision': 'INT8',\n",
        "        'Size (MB)': f\"{ptq_results['ptq']['size_mb']:.4f}\",\n",
        "        'MAE': f\"{ptq_results['ptq']['mae']:.4f}\",\n",
        "        'Latency (ms)': f\"{ptq_results['ptq']['latency_ms']:.4f}\",\n",
        "    },\n",
        "    {\n",
        "        'Model': 'QAT',\n",
        "        'Precision': 'INT8',\n",
        "        'Size (MB)': f\"{qat_results['qat']['size_mb']:.4f}\",\n",
        "        'MAE': f\"{qat_results['qat']['mae']:.4f}\",\n",
        "        'Latency (ms)': f\"{qat_results['qat']['latency_ms']:.4f}\",\n",
        "    },\n",
        "]\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"=\"*60)\n",
        "print(\"Final Comparison Results\")\n",
        "print(\"=\"*60)\n",
        "print(comparison_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 상세 비교 분석\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Detailed Comparison Analysis\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n1. Accuracy (MAE):\")\n",
        "print(f\"   Baseline: {baseline_performance['mae']:.4f}\")\n",
        "print(f\"   PTQ:      {ptq_results['ptq']['mae']:.4f} (Drop: {ptq_results['ptq']['mae_drop']:.4f}, {ptq_results['ptq']['mae_drop_percent']:.2f}%)\")\n",
        "print(f\"   QAT:      {qat_results['qat']['mae']:.4f} (Drop: {qat_results['qat']['mae_drop']:.4f}, {qat_results['qat']['mae_drop_percent']:.2f}%)\")\n",
        "\n",
        "mae_diff = ptq_results['ptq']['mae'] - qat_results['qat']['mae']\n",
        "print(f\"   QAT vs PTQ: {mae_diff:.4f} {'(QAT better)' if mae_diff > 0 else '(PTQ better)'}\")\n",
        "\n",
        "print(f\"\\n2. Model Size:\")\n",
        "print(f\"   Baseline: {baseline_performance['size_mb']:.4f} MB\")\n",
        "print(f\"   PTQ:      {ptq_results['ptq']['size_mb']:.4f} MB (Reduction: {ptq_results['ptq']['size_reduction_mb']:.4f} MB, {ptq_results['ptq']['size_reduction_percent']:.2f}%)\")\n",
        "print(f\"   QAT:      {qat_results['qat']['size_mb']:.4f} MB (Reduction: {qat_results['qat']['size_reduction_mb']:.4f} MB, {qat_results['qat']['size_reduction_percent']:.2f}%)\")\n",
        "\n",
        "print(f\"\\n3. Latency:\")\n",
        "print(f\"   Baseline: {baseline_performance['latency_ms']:.4f} ms/video\")\n",
        "print(f\"   PTQ:      {ptq_results['ptq']['latency_ms']:.4f} ms/video (Improvement: {ptq_results['ptq']['latency_improvement_ms']:.4f} ms, {ptq_results['ptq']['latency_improvement_percent']:.2f}%)\")\n",
        "print(f\"   QAT:      {qat_results['qat']['latency_ms']:.4f} ms/video (Improvement: {qat_results['qat']['latency_improvement_ms']:.4f} ms, {qat_results['qat']['latency_improvement_percent']:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 결과 시각화 (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결과 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "models = ['Baseline\\n(FP32)', 'PTQ\\n(INT8)', 'QAT\\n(INT8)']\n",
        "x = np.arange(len(models))\n",
        "\n",
        "# MAE 비교\n",
        "mae_values = [\n",
        "    baseline_performance['mae'],\n",
        "    ptq_results['ptq']['mae'],\n",
        "    qat_results['qat']['mae'],\n",
        "]\n",
        "axes[0].bar(x, mae_values, color=['blue', 'orange', 'green'])\n",
        "axes[0].set_ylabel('MAE')\n",
        "axes[0].set_title('Mean Absolute Error')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(models)\n",
        "axes[0].grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "# Model Size 비교\n",
        "size_values = [\n",
        "    baseline_performance['size_mb'],\n",
        "    ptq_results['ptq']['size_mb'],\n",
        "    qat_results['qat']['size_mb'],\n",
        "]\n",
        "axes[1].bar(x, size_values, color=['blue', 'orange', 'green'])\n",
        "axes[1].set_ylabel('Size (MB)')\n",
        "axes[1].set_title('Model Size')\n",
        "axes[1].set_xticks(x)\n",
        "axes[1].set_xticklabels(models)\n",
        "axes[1].grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "# Latency 비교\n",
        "latency_values = [\n",
        "    baseline_performance['latency_ms'],\n",
        "    ptq_results['ptq']['latency_ms'],\n",
        "    qat_results['qat']['latency_ms'],\n",
        "]\n",
        "axes[2].bar(x, latency_values, color=['blue', 'orange', 'green'])\n",
        "axes[2].set_ylabel('Latency (ms/video)')\n",
        "axes[2].set_title('Inference Latency')\n",
        "axes[2].set_xticks(x)\n",
        "axes[2].set_xticklabels(models)\n",
        "axes[2].grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 결과 파일 다운로드 (Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결과 파일 다운로드\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# 결과 디렉토리 확인\n",
        "results_dir = config.RESULTS_DIR\n",
        "print(f\"Results directory: {results_dir}\")\n",
        "print(f\"Files in results directory:\")\n",
        "for f in results_dir.glob(\"*\"):\n",
        "    print(f\"  - {f.name}\")\n",
        "\n",
        "# 결과 파일들을 zip으로 압축\n",
        "zip_path = \"/content/quantization_results.zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for file_path in results_dir.glob(\"*\"):\n",
        "        zipf.write(file_path, file_path.name)\n",
        "    # 체크포인트도 포함 (선택사항)\n",
        "    # for file_path in config.CHECKPOINT_DIR.glob(\"*.pth\"):\n",
        "    #     zipf.write(file_path, f\"checkpoints/{file_path.name}\")\n",
        "\n",
        "print(f\"\\nResults zipped to: {zip_path}\")\n",
        "\n",
        "# 다운로드\n",
        "files.download(zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. 전체 실험 한 번에 실행 (Alternative)\n",
        "\n",
        "위의 단계별 실행 대신, `run_all.py`를 사용하여 전체 실험을 한 번에 실행할 수도 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 전체 실험 한 번에 실행 (선택사항)\n",
        "# 주의: 이 방법은 baseline을 새로 학습합니다\n",
        "# 이미 학습된 모델이 있다면 위의 단계별 실행을 권장합니다\n",
        "\n",
        "# all_results = run_all_experiments(\n",
        "#     train_baseline=True,  # False로 설정하면 기존 체크포인트 사용\n",
        "#     save_results=True,\n",
        "#     verbose=True,\n",
        "# )\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
