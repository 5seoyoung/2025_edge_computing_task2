{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quantization 비교 실험 - EchoNet-Dynamic EF 회귀 모델\n",
        "\n",
        "이 노트북은 Post-Training Quantization (PTQ)와 Quantization-Aware Training (QAT)를 비교하는 실험을 수행합니다.\n",
        "\n",
        "## 실험 목표\n",
        "- Baseline (FP32) 모델 학습\n",
        "- PTQ 적용 및 성능 측정\n",
        "- QAT 적용 및 성능 측정\n",
        "- 세 모델의 MAE, Model Size, Latency 비교\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 환경 체크 및 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU/CPU 체크\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"\\nUsing device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요한 패키지 설치\n",
        "%pip install -q opencv-python pandas tqdm matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 방법 1: GitHub에서 클론 (권장)\n",
        "!git clone https://github.com/5seoyoung/2025_edge_computing_task2.git\n",
        "import sys\n",
        "sys.path.append('/content/2025_edge_computing_task2')\n",
        "\n",
        "# 방법 2: 파일 직접 업로드\n",
        "# from google.colab import files\n",
        "# files.upload()  # config.py, dataset.py, model.py 등을 업로드\n",
        "# sys.path.append('/content')\n",
        "\n",
        "# 현재 디렉토리 확인\n",
        "import os\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "print(f\"Files in current directory: {os.listdir('.')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 데이터 준비\n",
        "\n",
        "### 옵션 A: Google Drive 마운트 (권장)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 전체 데이터 경로 설정 (Drive에 전체 데이터가 있는 경우)\n",
        "# 샘플 데이터를 사용하려면 아래 \"옵션 B: 샘플 데이터 사용\" 셀을 사용하세요\n",
        "FULL_DATA_ROOT = \"/content/drive/MyDrive/echonet_dynamic\"  # 여기를 실제 경로로 수정하세요\n",
        "\n",
        "# 전체 데이터를 사용할 경우\n",
        "# DATA_ROOT = FULL_DATA_ROOT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 옵션 B: 샘플 데이터 사용 (전체 데이터가 너무 큰 경우)\n",
        "\n",
        "이미 Drive에 준비된 샘플 데이터를 사용하거나, 아래 코드로 샘플 데이터를 생성할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 샘플 데이터 사용 설정\n",
        "USE_SAMPLE_DATA = True  # True: 샘플 데이터 사용, False: 전체 데이터 사용\n",
        "\n",
        "if USE_SAMPLE_DATA:\n",
        "    # 이미 Drive에 준비된 샘플 데이터 경로\n",
        "    # 폴더 구조: sample_echonet_dynamic/Videos/*.avi, sample_echonet_dynamic/FileList.csv\n",
        "    DATA_ROOT = \"/content/drive/MyDrive/sample_echonet_dynamic\"  # 여기를 실제 경로로 수정\n",
        "    \n",
        "    from pathlib import Path\n",
        "    sample_path = Path(DATA_ROOT)\n",
        "    \n",
        "    if sample_path.exists():\n",
        "        # 샘플 데이터 정보 확인\n",
        "        filelist_path = sample_path / \"FileList.csv\"\n",
        "        video_dir = sample_path / \"Videos\"\n",
        "        \n",
        "        if filelist_path.exists() and video_dir.exists():\n",
        "            import pandas as pd\n",
        "            df = pd.read_csv(filelist_path)\n",
        "            video_count = len(list(video_dir.glob(\"*.avi\")))\n",
        "            \n",
        "            print(f\"✅ Sample dataset found:\")\n",
        "            print(f\"  Location: {DATA_ROOT}\")\n",
        "            print(f\"  Videos in FileList.csv: {len(df)}\")\n",
        "            print(f\"  Video files in Videos/: {video_count}\")\n",
        "            \n",
        "            # Split distribution 확인\n",
        "            if 'Split' in df.columns:\n",
        "                print(f\"\\nSplit distribution:\")\n",
        "                for split in ['TRAIN', 'VAL', 'TEST']:\n",
        "                    count = len(df[df['Split'] == split])\n",
        "                    print(f\"  {split}: {count}\")\n",
        "            else:\n",
        "                print(f\"\\nFileList columns: {df.columns.tolist()}\")\n",
        "        else:\n",
        "            print(f\"❌ Sample dataset structure incorrect!\")\n",
        "            print(f\"  Expected: {filelist_path}\")\n",
        "            print(f\"  Expected: {video_dir}\")\n",
        "            DATA_ROOT = None\n",
        "    else:\n",
        "        print(f\"❌ Sample dataset not found at {DATA_ROOT}\")\n",
        "        print(\"Please check the path or upload sample data to Drive\")\n",
        "        DATA_ROOT = None\n",
        "else:\n",
        "    # 전체 데이터 사용\n",
        "    DATA_ROOT = \"/content/drive/MyDrive/echonet_dynamic\"  # 여기를 실제 경로로 수정\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 설정 및 모듈 임포트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime\n",
        "import sys\n",
        "\n",
        "# 프로젝트 경로 추가\n",
        "sys.path.append('/content/2025_edge_computing_task2')\n",
        "\n",
        "# 모듈 임포트\n",
        "import config\n",
        "from dataset import get_dataloaders\n",
        "from model import create_model\n",
        "from train import train_model, load_checkpoint\n",
        "from quant_utils import apply_ptq, apply_qat\n",
        "from metrics import evaluate_model_performance\n",
        "from main_ptq import run_ptq_experiment\n",
        "from main_qat import run_qat_experiment\n",
        "from run_all import run_all_experiments\n",
        "\n",
        "# Colab용 설정 업데이트\n",
        "# 위에서 설정한 DATA_ROOT를 사용\n",
        "if 'DATA_ROOT' in locals() and DATA_ROOT is not None:\n",
        "    config.BASE_DIR = Path(DATA_ROOT)\n",
        "    config.VIDEO_DIR = config.BASE_DIR / \"Videos\"\n",
        "    config.FILELIST_PATH = config.BASE_DIR / \"FileList.csv\"\n",
        "    print(f\"✅ Using data from: {config.BASE_DIR}\")\n",
        "else:\n",
        "    print(\"❌ DATA_ROOT not set! Please run data preparation cells above.\")\n",
        "    raise ValueError(\"DATA_ROOT must be set. Check data preparation section.\")\n",
        "\n",
        "# 디렉토리 생성\n",
        "config.RESULTS_DIR.mkdir(exist_ok=True, parents=True)\n",
        "config.CHECKPOINT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# 디바이스 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config.DEVICE = device\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Data root: {config.BASE_DIR}\")\n",
        "print(f\"Video dir: {config.VIDEO_DIR}\")\n",
        "print(f\"FileList: {config.FILELIST_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 데이터 로딩\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 경로 확인\n",
        "if not config.VIDEO_DIR.exists():\n",
        "    raise FileNotFoundError(f\"Video directory not found: {config.VIDEO_DIR}\")\n",
        "if not config.FILELIST_PATH.exists():\n",
        "    raise FileNotFoundError(f\"FileList.csv not found: {config.FILELIST_PATH}\")\n",
        "\n",
        "# 데이터 로더 생성\n",
        "print(\"Loading dataset...\")\n",
        "train_loader, val_loader = get_dataloaders(\n",
        "    video_dir=config.VIDEO_DIR,\n",
        "    filelist_path=config.FILELIST_PATH,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    num_workers=0,  # Colab에서는 0 권장\n",
        "    num_frames=config.NUM_FRAMES,\n",
        "    img_size=config.IMG_SIZE,\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_loader.dataset)}\")\n",
        "print(f\"Val samples: {len(val_loader.dataset)}\")\n",
        "\n",
        "# Latency 측정용 샘플 입력 준비\n",
        "sample_videos, _ = next(iter(val_loader))\n",
        "sample_input = sample_videos[:1].to(device)\n",
        "print(f\"\\nSample video shape: {sample_videos.shape}\")  # (B, N, C, H, W)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Baseline 모델 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline 모델 생성\n",
        "baseline_model = create_model()\n",
        "print(f\"Model created: {baseline_model.__class__.__name__}\")\n",
        "\n",
        "# 모델 파라미터 수 확인\n",
        "total_params = sum(p.numel() for p in baseline_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in baseline_model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "baseline_checkpoint_path = config.CHECKPOINT_DIR / \"best_model.pth\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline 모델 학습 또는 로드\n",
        "if not baseline_checkpoint_path.exists():\n",
        "    print(\"Training baseline model...\")\n",
        "    history = train_model(\n",
        "        baseline_model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        num_epochs=config.NUM_EPOCHS,\n",
        "        learning_rate=config.LEARNING_RATE,\n",
        "        weight_decay=config.WEIGHT_DECAY,\n",
        "        device=device,\n",
        "        checkpoint_dir=config.CHECKPOINT_DIR,\n",
        "        save_best=True,\n",
        "        verbose=True,\n",
        "    )\n",
        "    \n",
        "    # 최종 모델 저장\n",
        "    torch.save(baseline_model.state_dict(), baseline_checkpoint_path)\n",
        "    print(f\"Baseline model saved to {baseline_checkpoint_path}\")\n",
        "else:\n",
        "    print(f\"Loading baseline model from {baseline_checkpoint_path}\")\n",
        "    baseline_model.load_state_dict(torch.load(baseline_checkpoint_path, map_location=device))\n",
        "    baseline_model = baseline_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 학습 히스토리 시각화 (optional)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if 'history' in locals():\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    \n",
        "    # Loss\n",
        "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
        "    axes[0].plot(history['val_loss'], label='Val Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # MAE\n",
        "    axes[1].plot(history['val_mae'], label='Val MAE')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('MAE')\n",
        "    axes[1].set_title('Validation MAE')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Baseline 모델 평가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline 평가\n",
        "print(\"Evaluating baseline model...\")\n",
        "baseline_model.eval()\n",
        "criterion = nn.MSELoss()\n",
        "baseline_performance = evaluate_model_performance(\n",
        "    baseline_model,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    device=device,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "baseline_summary = {\n",
        "    'model_type': 'baseline',\n",
        "    'MAE': baseline_performance['mae'],\n",
        "    'size_mb': baseline_performance['size_mb'],\n",
        "    'latency_ms_per_video': baseline_performance['latency_ms']\n",
        "}\n",
        "\n",
        "print(f\"\\nBaseline Results:\")\n",
        "print(f\"  MAE: {baseline_summary['MAE']:.4f}\")\n",
        "print(f\"  Model Size: {baseline_summary['size_mb']:.4f} MB\")\n",
        "print(f\"  Latency: {baseline_summary['latency_ms_per_video']:.4f} ms/video\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Post-Training Quantization (PTQ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PTQ 실험 실행\n",
        "ptq_results = run_ptq_experiment(\n",
        "    baseline_checkpoint_path=baseline_checkpoint_path,\n",
        "    save_results=True,\n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Quantization-Aware Training (QAT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# QAT 실험 실행\n",
        "qat_results = run_qat_experiment(\n",
        "    baseline_checkpoint_path=baseline_checkpoint_path,\n",
        "    save_results=True,\n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 최종 비교 결과\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 전체 결과 비교 테이블 생성\n",
        "import pandas as pd\n",
        "\n",
        "comparison_data = [\n",
        "    {\n",
        "        'Model': 'FP32 Baseline',\n",
        "        'Precision': 'FP32',\n",
        "        'Size (MB)': f\"{baseline_summary['size_mb']:.4f}\",\n",
        "        'MAE': f\"{baseline_summary['MAE']:.4f}\",\n",
        "        'Latency (ms)': f\"{baseline_summary['latency_ms_per_video']:.4f}\",\n",
        "    },\n",
        "    {\n",
        "        'Model': 'PTQ',\n",
        "        'Precision': 'INT8',\n",
        "        'Size (MB)': f\"{ptq_results['ptq']['size_mb']:.4f}\",\n",
        "        'MAE': f\"{ptq_results['ptq']['mae']:.4f}\",\n",
        "        'Latency (ms)': f\"{ptq_results['ptq']['latency_ms']:.4f}\",\n",
        "    },\n",
        "    {\n",
        "        'Model': 'QAT',\n",
        "        'Precision': 'INT8',\n",
        "        'Size (MB)': f\"{qat_results['qat']['size_mb']:.4f}\",\n",
        "        'MAE': f\"{qat_results['qat']['mae']:.4f}\",\n",
        "        'Latency (ms)': f\"{qat_results['qat']['latency_ms']:.4f}\",\n",
        "    },\n",
        "]\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"=\"*60)\n",
        "print(\"Final Comparison Results\")\n",
        "print(\"=\"*60)\n",
        "print(comparison_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 상세 비교 분석\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Detailed Comparison Analysis\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n1. Accuracy (MAE):\")\n",
        "print(f\"   Baseline: {baseline_summary['MAE']:.4f}\")\n",
        "print(f\"   PTQ:      {ptq_results['ptq']['mae']:.4f} (Drop: {ptq_results['ptq']['mae_drop']:.4f}, {ptq_results['ptq']['mae_drop_percent']:.2f}%)\")\n",
        "print(f\"   QAT:      {qat_results['qat']['mae']:.4f} (Drop: {qat_results['qat']['mae_drop']:.4f}, {qat_results['qat']['mae_drop_percent']:.2f}%)\")\n",
        "\n",
        "mae_diff = ptq_results['ptq']['mae'] - qat_results['qat']['mae']\n",
        "print(f\"   QAT vs PTQ: {mae_diff:.4f} {'(QAT better)' if mae_diff > 0 else '(PTQ better)'}\")\n",
        "\n",
        "print(f\"\\n2. Model Size:\")\n",
        "print(f\"   Baseline: {baseline_summary['size_mb']:.4f} MB\")\n",
        "print(f\"   PTQ:      {ptq_results['ptq']['size_mb']:.4f} MB (Reduction: {ptq_results['ptq']['size_reduction_mb']:.4f} MB, {ptq_results['ptq']['size_reduction_percent']:.2f}%)\")\n",
        "print(f\"   QAT:      {qat_results['qat']['size_mb']:.4f} MB (Reduction: {qat_results['qat']['size_reduction_mb']:.4f} MB, {qat_results['qat']['size_reduction_percent']:.2f}%)\")\n",
        "\n",
        "print(f\"\\n3. Latency:\")\n",
        "print(f\"   Baseline: {baseline_summary['latency_ms_per_video']:.4f} ms/video\")\n",
        "print(f\"   PTQ:      {ptq_results['ptq']['latency_ms']:.4f} ms/video (Improvement: {ptq_results['ptq']['latency_improvement_ms']:.4f} ms, {ptq_results['ptq']['latency_improvement_percent']:.2f}%)\")\n",
        "print(f\"   QAT:      {qat_results['qat']['latency_ms']:.4f} ms/video (Improvement: {qat_results['qat']['latency_improvement_ms']:.4f} ms, {qat_results['qat']['latency_improvement_percent']:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 결과 시각화 (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결과 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "models = ['Baseline\\n(FP32)', 'PTQ\\n(INT8)', 'QAT\\n(INT8)']\n",
        "x = np.arange(len(models))\n",
        "\n",
        "# MAE 비교\n",
        "mae_values = [\n",
        "    baseline_summary['MAE'],\n",
        "    ptq_results['ptq']['mae'],\n",
        "    qat_results['qat']['mae'],\n",
        "]\n",
        "axes[0].bar(x, mae_values, color=['blue', 'orange', 'green'])\n",
        "axes[0].set_ylabel('MAE')\n",
        "axes[0].set_title('Mean Absolute Error')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(models)\n",
        "axes[0].grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "# Model Size 비교\n",
        "size_values = [\n",
        "    baseline_summary['size_mb'],\n",
        "    ptq_results['ptq']['size_mb'],\n",
        "    qat_results['qat']['size_mb'],\n",
        "]\n",
        "axes[1].bar(x, size_values, color=['blue', 'orange', 'green'])\n",
        "axes[1].set_ylabel('Size (MB)')\n",
        "axes[1].set_title('Model Size')\n",
        "axes[1].set_xticks(x)\n",
        "axes[1].set_xticklabels(models)\n",
        "axes[1].grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "# Latency 비교\n",
        "latency_values = [\n",
        "    baseline_summary['latency_ms_per_video'],\n",
        "    ptq_results['ptq']['latency_ms'],\n",
        "    qat_results['qat']['latency_ms'],\n",
        "]\n",
        "axes[2].bar(x, latency_values, color=['blue', 'orange', 'green'])\n",
        "axes[2].set_ylabel('Latency (ms/video)')\n",
        "axes[2].set_title('Inference Latency')\n",
        "axes[2].set_xticks(x)\n",
        "axes[2].set_xticklabels(models)\n",
        "axes[2].grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 결과 파일 다운로드 (Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결과 파일 다운로드\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# 결과 디렉토리 확인\n",
        "results_dir = config.RESULTS_DIR\n",
        "print(f\"Results directory: {results_dir}\")\n",
        "print(f\"Files in results directory:\")\n",
        "for f in results_dir.glob(\"*\"):\n",
        "    print(f\"  - {f.name}\")\n",
        "\n",
        "# 결과 파일들을 zip으로 압축\n",
        "zip_path = \"/content/quantization_results.zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for file_path in results_dir.glob(\"*\"):\n",
        "        zipf.write(file_path, file_path.name)\n",
        "    # 체크포인트도 포함 (선택사항)\n",
        "    # for file_path in config.CHECKPOINT_DIR.glob(\"*.pth\"):\n",
        "    #     zipf.write(file_path, f\"checkpoints/{file_path.name}\")\n",
        "\n",
        "print(f\"\\nResults zipped to: {zip_path}\")\n",
        "\n",
        "# 다운로드\n",
        "files.download(zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. 전체 실험 한 번에 실행 (Alternative)\n",
        "\n",
        "위의 단계별 실행 대신, `run_all.py`를 사용하여 전체 실험을 한 번에 실행할 수도 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 전체 실험 한 번에 실행 (선택사항)\n",
        "# 주의: 이 방법은 baseline을 새로 학습합니다\n",
        "# 이미 학습된 모델이 있다면 위의 단계별 실행을 권장합니다\n",
        "\n",
        "# all_results = run_all_experiments(\n",
        "#     train_baseline=True,  # False로 설정하면 기존 체크포인트 사용\n",
        "#     save_results=True,\n",
        "#     verbose=True,\n",
        "# )\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
